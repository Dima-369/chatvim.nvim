# Changelog

- v0.3.2
  - Include leader key shortcuts by default.
- v0.3.1:
  - Add `:ChatvimWrite` command to write the current ephemeral chat.
- v0.3.0:
  - Switch to Chatvim CLI. Deprecate Codey.
- v0.2.0:
  - Use Codey for LLM streaming: github.com/codeybeaver/codey
  - Support Anthropic models
- v0.1.1:
  - Fix bug where models weren't used correctly.
- v0.1.0
  - Support `gpt-4o`-related models from OpenAI.
- v0.0.9
  - Support `gpt-4.1-mini`, `gpt-4.1-nano`, `o1`, `o1-mini`
- v0.0.8
  - Support `o3` and `o3-mini` models from OpenAI.
- v0.0.7:
  - Overhaul streaming to buffer every 500ms, fixing laggy updates.
  - Re-enable syntax highlighting during streaming.
- v0.0.6:
  - Support `gpt-4.1` from OpenAI.
  - Use promises-based API instead of callback-based API for readline.
- v0.0.5:
  - Include timeouts in js code to make hanging less likely.
- v0.0.4:
  - Add ":ChatVimStop" command to stop streaming.
- v0.0.3:
  - Write one chunk at a time, but ...
  - Disable syntax highlighting while streaming to prevent lag.
- v0.0.2:
  - Add "Computing..." spinner.
  - Write one line at a time (less lag).
- v0.0.1: Complete markdown documents with Grok.
